{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18046f0",
   "metadata": {},
   "source": [
    "### Problem-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a254f21",
   "metadata": {},
   "source": [
    "You are provided with a protein dataset. Learn a Decision Tree regressor/classifier \n",
    "and Random Forest (RF) regressor/classifier on the dataset separately and report \n",
    "your results with observation as mentioned below. You should optimize \n",
    "hyperparameters available for both Decision tree and RF regressor/classifier \n",
    "should report best results only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd257cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b333f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     gauss1      gauss2  repulsion  hydrophobic  hydrogen\n",
       " 0  48.02108   434.90009    1.00229     17.16027   1.04153\n",
       " 1  45.86394   906.54910    4.54990      0.00000   7.21115\n",
       " 2  49.45446   708.90695    4.56065     10.12192   5.42312\n",
       " 3  54.99922   768.05907    5.70052     31.01157   2.34365\n",
       " 4  53.45864  1053.90858    1.63114      0.00000   2.94989,\n",
       "    affinity\n",
       " 0 -2.745424\n",
       " 1 -2.745424\n",
       " 2 -2.745424\n",
       " 3 -2.745424\n",
       " 4 -2.814060)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing train data\n",
    "X_train = pd.read_csv('Dataset-assignment-6/Train data/X_train.csv', sep=' ')\n",
    "y_train = pd.read_csv('Dataset-assignment-6/Train data/Y_train.csv')\n",
    "X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f182a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     gauss1      gauss2  repulsion  hydrophobic  hydrogen\n",
       " 0  89.12005  1011.21787    4.03982     20.12528   2.20970\n",
       " 1  77.28506   885.98707    7.25603      0.00000   7.58789\n",
       " 2  41.04995   572.64999    0.76219      6.28351   1.36514\n",
       " 3  91.11996   979.83764    7.17185      0.00000  10.09426\n",
       " 4  65.07444   776.79753    5.83319      0.00000   8.87687,\n",
       "    affinity\n",
       " 0 -2.841514\n",
       " 1 -3.061148\n",
       " 2 -3.116057\n",
       " 3 -3.129784\n",
       " 4 -3.225874)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing test data\n",
    "X_test = pd.read_csv('Dataset-assignment-6/test data/X_test.csv', sep=' ')\n",
    "y_test = pd.read_csv('Dataset-assignment-6/test data/Y_test.csv')\n",
    "X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed027acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13948503, 0.0419371 , 0.0410062 , 0.0959188 , 0.04567277],\n",
       "       [0.13206004, 0.16187828, 0.2061618 , 0.        , 0.31622054],\n",
       "       [0.1444188 , 0.11161753, 0.20666226, 0.05657734, 0.23781254],\n",
       "       ...,\n",
       "       [0.44118946, 0.31607728, 0.21063937, 0.19760863, 0.16320429],\n",
       "       [0.46194503, 0.41481286, 0.16549963, 0.30679929, 0.14498921],\n",
       "       [0.31672902, 0.2813191 , 0.38883103, 0.03427746, 0.42804302]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61fbce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#defining function for calculating mse for regressor\n",
    "def mse_calculation(model, X, y):\n",
    "    return mean_squared_error(y, model.predict(X))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3990da",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4aab40",
   "metadata": {},
   "source": [
    "###### Without hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a8d04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data   :0.0\n",
      "MSE for test data    :11.065065213808497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"MSE for train data   :{}\".format(mse_calculation(tree, X_train, y_train)))\n",
    "print(\"MSE for test data    :{}\".format(mse_calculation(tree, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2762da",
   "metadata": {},
   "source": [
    "###### With hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09863e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
      "\n",
      "Best Parameters for Decision Tree:\n",
      "{'criterion': 'mae', 'max_depth': 10, 'min_samples_leaf': 15, 'min_samples_split': 2, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "#parameter for tuning\n",
    "tree_params = {\n",
    "    \"criterion\":(\"mse\", \"mae\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    \"max_depth\":(list(range(1, 20))), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "#grid search for best parameters\n",
    "model_tree = DecisionTreeRegressor(random_state=10)\n",
    "tree_cv = GridSearchCV(model_tree, tree_params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "best_tree_params = tree_cv.best_params_\n",
    "print('\\nBest Parameters for Decision Tree:\\n{}'.format(best_tree_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4456b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data   :4.841743362893848\n",
      "MSE for test data    :6.928168829427344\n"
     ]
    }
   ],
   "source": [
    "best_tree = DecisionTreeRegressor(**best_tree_params)                  #best DT regressor\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "#mse for train and test data\n",
    "print(\"MSE for train data   :{}\".format(mse_calculation(best_tree, X_train, y_train)))\n",
    "print(\"MSE for test data    :{}\".format(mse_calculation(best_tree, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459faf7",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee21dce",
   "metadata": {},
   "source": [
    "###### Without hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8734a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\favas\\AppData\\Local\\Temp/ipykernel_8908/3643658931.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data   :0.6231256019693173\n",
      "MSE for test data    :6.630470026107928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(random_state=10)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "#mse for train and test data\n",
    "print(\"MSE for train data   :{}\".format(mse_calculation(forest, X_train, y_train)))\n",
    "print(\"MSE for test data    :{}\".format(mse_calculation(forest, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd506e8",
   "metadata": {},
   "source": [
    "###### With hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d30d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
      "\n",
      "Best Parameters for Random Forest:\n",
      "{'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "#parameters for tuning\n",
    "forest_params = {\n",
    "    \"n_estimators\":list(range(40,101,20)), \n",
    "    \"max_depth\":list(range(1, 20)), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "#grid search for best parametere\n",
    "model_forest = RandomForestRegressor(random_state=1)\n",
    "forest_cv = GridSearchCV(model_forest, forest_params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1,verbose=1)\n",
    "forest_cv.fit(X_train, y_train)\n",
    "\n",
    "best_forest_params = forest_cv.best_params_\n",
    "print('\\nBest Parameters for Random Forest:\\n{}'.format(best_forest_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8e5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data    :0.024854683729660536\n",
      "MSE for test data     :0.06975705797089972\n"
     ]
    }
   ],
   "source": [
    "best_forest = RandomForestRegressor(**best_forest_params)                #best random forest regressor\n",
    "best_forest.fit(X_train, y_train)\n",
    "\n",
    "#calculation of mse for train and test data\n",
    "print(\"MSE for train data    :{}\".format(mse_calculation(best_forest, X_train, y_train)))\n",
    "print(\"MSE for test data     :{}\".format(mse_calculation(best_forest, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee15cc1",
   "metadata": {},
   "source": [
    "### Problem-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62499359",
   "metadata": {},
   "source": [
    "Generate a random n-class classification problem(Hint: may use \n",
    "make_classification method from sklearn.datasets) and implement \n",
    "AdaBoostClassifier on this custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "164aa16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#define a function for printing different classification performace parameters\n",
    "def print_score(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    clf_report = pd.DataFrame(classification_report(y, y_pred,output_dict=True)).round(2)\n",
    "    print(f\"Accuracy Score: {accuracy_score(y, y_pred) * 100:.2f}%\")\n",
    "    print(f\"\\nClassification Report:\\n{clf_report}\")\n",
    "    print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y, y_pred)}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dbbf1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#creating a dataset with 3 classes and 6 features\n",
    "X, y = make_classification(n_samples=3000, n_classes=2, n_features=6, n_informative=3, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4522839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "______________________\n",
      "Accuracy Score: 96.71%\n",
      "\n",
      "Classification Report:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision     0.96     0.97      0.97       0.97          0.97\n",
      "recall        0.97     0.96      0.97       0.97          0.97\n",
      "f1-score      0.97     0.97      0.97       0.97          0.97\n",
      "support    1045.00  1055.00      0.97    2100.00       2100.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1016   29]\n",
      " [  40 1015]]\n",
      "\n",
      "Test Data\n",
      "______________________\n",
      "Accuracy Score: 94.44%\n",
      "\n",
      "Classification Report:\n",
      "                0       1  accuracy  macro avg  weighted avg\n",
      "precision    0.95    0.94      0.94       0.94          0.94\n",
      "recall       0.94    0.95      0.94       0.94          0.94\n",
      "f1-score     0.94    0.94      0.94       0.94          0.94\n",
      "support    450.00  450.00      0.94     900.00        900.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[421  29]\n",
      " [ 21 429]]\n"
     ]
    }
   ],
   "source": [
    "#Ada boost classificaion\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=42)              \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#printing performance parameters\n",
    "print('Train Data\\n______________________')\n",
    "print_score(clf, X_train, y_train)\n",
    "\n",
    "print('\\nTest Data\\n______________________')\n",
    "print_score(clf, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
