{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fc6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7298ed",
   "metadata": {},
   "source": [
    "### Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba654329",
   "metadata": {},
   "source": [
    "##### Learn a model which can classify given data correctly. This is a multiclass data imbalance problem with high dimensions data. You can see the classes are named as n, p1, p2, p3,...So the classes as n are negative ones and with p in it as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64cff127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.190000e-06</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>p4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.080000e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-2.900000e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.031992</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49315</td>\n",
       "      <td>9.1182</td>\n",
       "      <td>15.4610</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.950000e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>p5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.680000e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610000e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>p5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2             3         4         5  \\\n",
       "0 -6.190000e-06 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116   \n",
       "1 -5.080000e-07 -0.000008 -0.000010 -2.900000e-06 -0.000001  0.000046   \n",
       "2  2.950000e-06  0.000036  0.000004  1.580000e-05  0.000098 -0.000337   \n",
       "3 -1.680000e-05  0.000026  0.000518  1.550000e-05  0.000072  0.000032   \n",
       "4  1.610000e-06  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036   \n",
       "\n",
       "          6         7         8         9  ...       39      40       41  \\\n",
       "0  0.027253  0.027290  0.027220  0.017966  ... -0.69694  1.6505   3.7807   \n",
       "1  0.031973  0.031981  0.031992 -0.036266  ... -0.49315  9.1182  15.4610   \n",
       "2  0.010780  0.010744  0.010740 -0.018368  ... -0.68272  1.8947   5.9028   \n",
       "3 -0.037939 -0.037965 -0.038483 -0.030257  ... -0.71862  1.9076   5.5017   \n",
       "4  0.010411  0.010393  0.010549 -0.014548  ... -0.71715  1.0778   4.9960   \n",
       "\n",
       "       42      43      44      45      46      47  48  \n",
       "0 -1.5016 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940  p4  \n",
       "1 -1.4980 -1.4980 -1.4980 -1.4978 -1.4978 -1.4978   n  \n",
       "2 -1.4970 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036  p5  \n",
       "3 -1.4962 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017  p1  \n",
       "4 -1.5042 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915  p5  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d336616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8.507000e+03</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-8.104282e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.015471</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>-0.016507</td>\n",
       "      <td>...</td>\n",
       "      <td>8.297015</td>\n",
       "      <td>-0.635826</td>\n",
       "      <td>7.031227</td>\n",
       "      <td>8.142438</td>\n",
       "      <td>-1.501420</td>\n",
       "      <td>-1.501451</td>\n",
       "      <td>-1.501339</td>\n",
       "      <td>-1.497626</td>\n",
       "      <td>-1.497649</td>\n",
       "      <td>-1.497529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>8.580479e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>...</td>\n",
       "      <td>6.660245</td>\n",
       "      <td>1.607126</td>\n",
       "      <td>11.689025</td>\n",
       "      <td>6.417985</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.003015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.002209</td>\n",
       "      <td>-4.170000e-05</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>-0.055309</td>\n",
       "      <td>-0.055316</td>\n",
       "      <td>-0.055328</td>\n",
       "      <td>-0.061243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712110</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>-0.535610</td>\n",
       "      <td>0.606140</td>\n",
       "      <td>-1.512400</td>\n",
       "      <td>-1.512400</td>\n",
       "      <td>-1.511800</td>\n",
       "      <td>-1.510400</td>\n",
       "      <td>-1.510400</td>\n",
       "      <td>-1.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-5.435000e-06</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.035379</td>\n",
       "      <td>...</td>\n",
       "      <td>4.409750</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>1.500250</td>\n",
       "      <td>4.322250</td>\n",
       "      <td>-1.504100</td>\n",
       "      <td>-1.504100</td>\n",
       "      <td>-1.504000</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>-1.499300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.740000e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.028206</td>\n",
       "      <td>...</td>\n",
       "      <td>6.496200</td>\n",
       "      <td>-0.668240</td>\n",
       "      <td>3.235400</td>\n",
       "      <td>6.343600</td>\n",
       "      <td>-1.500800</td>\n",
       "      <td>-1.500800</td>\n",
       "      <td>-1.500700</td>\n",
       "      <td>-1.497900</td>\n",
       "      <td>-1.497900</td>\n",
       "      <td>-1.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>3.790000e-06</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.025535</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>...</td>\n",
       "      <td>9.822150</td>\n",
       "      <td>-0.578400</td>\n",
       "      <td>7.891750</td>\n",
       "      <td>9.731400</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.496100</td>\n",
       "      <td>-1.496100</td>\n",
       "      <td>-1.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>7.080000e-05</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.046319</td>\n",
       "      <td>0.046329</td>\n",
       "      <td>0.071934</td>\n",
       "      <td>...</td>\n",
       "      <td>89.372000</td>\n",
       "      <td>146.340000</td>\n",
       "      <td>145.860000</td>\n",
       "      <td>98.758000</td>\n",
       "      <td>-1.458500</td>\n",
       "      <td>-1.466200</td>\n",
       "      <td>-1.472600</td>\n",
       "      <td>-1.488400</td>\n",
       "      <td>-1.488400</td>\n",
       "      <td>-1.486800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2             3            4  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8.507000e+03  8507.000000   \n",
       "mean     -0.000001     0.000007     0.000015 -8.104282e-07     0.000010   \n",
       "std       0.000064     0.000069     0.000230  8.580479e-06     0.000038   \n",
       "min      -0.000678    -0.002163    -0.002209 -4.170000e-05    -0.000260   \n",
       "25%      -0.000006    -0.000007    -0.000065 -5.435000e-06    -0.000006   \n",
       "50%      -0.000002     0.000004     0.000003 -1.740000e-06     0.000004   \n",
       "75%       0.000002     0.000026     0.000089  3.790000e-06     0.000029   \n",
       "max       0.005784     0.004525     0.003330  7.080000e-05     0.000348   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000  ...   \n",
       "mean      0.000011     0.015471     0.015463     0.015448    -0.016507  ...   \n",
       "std       0.000217     0.015712     0.015715     0.015722     0.027911  ...   \n",
       "min      -0.001626    -0.055309    -0.055316    -0.055328    -0.061243  ...   \n",
       "25%      -0.000065     0.012665     0.012656     0.012658    -0.035379  ...   \n",
       "50%       0.000002     0.019684     0.019680     0.019674    -0.028206  ...   \n",
       "75%       0.000078     0.025535     0.025531     0.025518     0.004998  ...   \n",
       "max       0.001982     0.046324     0.046319     0.046329     0.071934  ...   \n",
       "\n",
       "                38           39           40           41           42  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000   \n",
       "mean      8.297015    -0.635826     7.031227     8.142438    -1.501420   \n",
       "std       6.660245     1.607126    11.689025     6.417985     0.003717   \n",
       "min       0.712110    -0.891000    -0.535610     0.606140    -1.512400   \n",
       "25%       4.409750    -0.717045     1.500250     4.322250    -1.504100   \n",
       "50%       6.496200    -0.668240     3.235400     6.343600    -1.500800   \n",
       "75%       9.822150    -0.578400     7.891750     9.731400    -1.498500   \n",
       "max      89.372000   146.340000   145.860000    98.758000    -1.458500   \n",
       "\n",
       "                43           44           45           46           47  \n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000  \n",
       "mean     -1.501451    -1.501339    -1.497626    -1.497649    -1.497529  \n",
       "std       0.003720     0.003670     0.002998     0.002996     0.003015  \n",
       "min      -1.512400    -1.511800    -1.510400    -1.510400    -1.510500  \n",
       "25%      -1.504100    -1.504000    -1.499400    -1.499400    -1.499300  \n",
       "50%      -1.500800    -1.500700    -1.497900    -1.497900    -1.497800  \n",
       "75%      -1.498500    -1.498500    -1.496100    -1.496100    -1.496000  \n",
       "max      -1.466200    -1.472600    -1.488400    -1.488400    -1.486800  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9158a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples                    :8507\n",
      "No.of samples with label 'n'      :4268\n",
      "No.of samples with label 'p1'     :853\n",
      "No.of samples with label 'p2'     :413\n",
      "No.of samples with label 'p3'     :651\n",
      "No.of samples with label 'p4'     :1253\n",
      "No.of samples with label 'p5'     :1069\n"
     ]
    }
   ],
   "source": [
    "# number of samples and count of each samples\n",
    "print(f\"No. of samples                    :{len(data)}\")\n",
    "print(f\"No.of samples with label 'n'      :{len(data[data.iloc[:,48]=='n'])}\")\n",
    "print(f\"No.of samples with label 'p1'     :{len(data[data.iloc[:,48]=='p1'])}\")\n",
    "print(f\"No.of samples with label 'p2'     :{len(data[data.iloc[:,48]=='p2'])}\")\n",
    "print(f\"No.of samples with label 'p3'     :{len(data[data.iloc[:,48]=='p3'])}\")\n",
    "print(f\"No.of samples with label 'p4'     :{len(data[data.iloc[:,48]=='p4'])}\")\n",
    "print(f\"No.of samples with label 'p5'     :{len(data[data.iloc[:,48]=='p5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb61a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is highly imbalanced, so split the data into positive and negative\n",
    "# all 'pi' labels as positive(1) and all 'n' label as negative(0)\n",
    "# do binary classification with this dataset\n",
    "# then split all positive labels in to p1, p2, p3, p4, and p5\n",
    "# do multilabel classification with this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea176707",
   "metadata": {},
   "source": [
    "###### Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf52dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.190000e-06</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.080000e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-2.900000e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.031992</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49315</td>\n",
       "      <td>9.1182</td>\n",
       "      <td>15.4610</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.950000e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.680000e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610000e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2             3         4         5  \\\n",
       "0 -6.190000e-06 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116   \n",
       "1 -5.080000e-07 -0.000008 -0.000010 -2.900000e-06 -0.000001  0.000046   \n",
       "2  2.950000e-06  0.000036  0.000004  1.580000e-05  0.000098 -0.000337   \n",
       "3 -1.680000e-05  0.000026  0.000518  1.550000e-05  0.000072  0.000032   \n",
       "4  1.610000e-06  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036   \n",
       "\n",
       "          6         7         8         9  ...       39      40       41  \\\n",
       "0  0.027253  0.027290  0.027220  0.017966  ... -0.69694  1.6505   3.7807   \n",
       "1  0.031973  0.031981  0.031992 -0.036266  ... -0.49315  9.1182  15.4610   \n",
       "2  0.010780  0.010744  0.010740 -0.018368  ... -0.68272  1.8947   5.9028   \n",
       "3 -0.037939 -0.037965 -0.038483 -0.030257  ... -0.71862  1.9076   5.5017   \n",
       "4  0.010411  0.010393  0.010549 -0.014548  ... -0.71715  1.0778   4.9960   \n",
       "\n",
       "       42      43      44      45      46      47  48  \n",
       "0 -1.5016 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940   1  \n",
       "1 -1.4980 -1.4980 -1.4980 -1.4978 -1.4978 -1.4978   0  \n",
       "2 -1.4970 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036   1  \n",
       "3 -1.4962 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017   1  \n",
       "4 -1.5042 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915   1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data split into positive and negative labels\n",
    "data_binary = data.copy()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data_binary.iloc[i,-1] == 'n':\n",
    "        data_binary.iloc[i,-1] = 0                 #put n label as 0 and others as 1\n",
    "    else:\n",
    "        data_binary.iloc[i,-1] = 1\n",
    "\n",
    "data_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb1ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-1.330000e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.019514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68758</td>\n",
       "      <td>11.5330</td>\n",
       "      <td>30.4150</td>\n",
       "      <td>-1.4991</td>\n",
       "      <td>-1.4992</td>\n",
       "      <td>-1.4993</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2             3         4         5         6  \\\n",
       "0 -0.000006 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116  0.027253   \n",
       "2  0.000003  0.000036  0.000004  1.580000e-05  0.000098 -0.000337  0.010780   \n",
       "3 -0.000017  0.000026  0.000518  1.550000e-05  0.000072  0.000032 -0.037939   \n",
       "4  0.000002  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036  0.010411   \n",
       "8 -0.000002 -0.000016  0.000046 -1.330000e-06  0.000008 -0.000092  0.011017   \n",
       "\n",
       "          7         8         9  ...       39       40       41      42  \\\n",
       "0  0.027290  0.027220  0.017966  ... -0.69694   1.6505   3.7807 -1.5016   \n",
       "2  0.010744  0.010740 -0.018368  ... -0.68272   1.8947   5.9028 -1.4970   \n",
       "3 -0.037965 -0.038483 -0.030257  ... -0.71862   1.9076   5.5017 -1.4962   \n",
       "4  0.010393  0.010549 -0.014548  ... -0.71715   1.0778   4.9960 -1.5042   \n",
       "8  0.011033  0.010987  0.019514  ... -0.68758  11.5330  30.4150 -1.4991   \n",
       "\n",
       "       43      44      45      46      47  48  \n",
       "0 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940   4  \n",
       "2 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036   5  \n",
       "3 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017   1  \n",
       "4 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915   5  \n",
       "8 -1.4992 -1.4993 -1.4986 -1.4986 -1.4984   2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for multi class classification\n",
    "# p1=1, p2=2, p3=3, p4=4, p5=5 \n",
    "data_multi = data[data.iloc[:,-1]!= 'n']       \n",
    "\n",
    "for i in range(len(data_multi)):\n",
    "    if data_multi.iloc[i,-1] == 'p1':\n",
    "        data_multi.iloc[i,-1] = 1\n",
    "    elif data_multi.iloc[i,-1] == 'p2':\n",
    "        data_multi.iloc[i,-1] = 2\n",
    "    elif data_multi.iloc[i,-1] == 'p3':\n",
    "        data_multi.iloc[i,-1] = 3\n",
    "    elif data_multi.iloc[i,-1] == 'p4':\n",
    "        data_multi.iloc[i,-1] = 4\n",
    "    elif data_multi.iloc[i,-1] == 'p5':\n",
    "        data_multi.iloc[i,-1] = 5\n",
    "\n",
    "data_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd920e",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c70ce",
   "metadata": {},
   "source": [
    "###### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a479c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do descision tree classification with positive and negative data in default arguments\n",
    "# find feature importance and select important features\n",
    "\n",
    "X = data_binary.iloc[:,:-1]\n",
    "y = data_binary.iloc[:,-1].astype(int)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)   \n",
    "importance = clf.feature_importances_              # get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de179a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00061\n",
      "Feature: 1, Score: 0.00205\n",
      "Feature: 2, Score: 0.00035\n",
      "Feature: 3, Score: 0.00085\n",
      "Feature: 4, Score: 0.00449\n",
      "Feature: 5, Score: 0.00030\n",
      "Feature: 6, Score: 0.10977\n",
      "Feature: 7, Score: 0.08512\n",
      "Feature: 8, Score: 0.10209\n",
      "Feature: 9, Score: 0.14378\n",
      "Feature: 10, Score: 0.14206\n",
      "Feature: 11, Score: 0.13885\n",
      "Feature: 12, Score: 0.01409\n",
      "Feature: 13, Score: 0.00712\n",
      "Feature: 14, Score: 0.00162\n",
      "Feature: 15, Score: 0.01372\n",
      "Feature: 16, Score: 0.00554\n",
      "Feature: 17, Score: 0.00558\n",
      "Feature: 18, Score: 0.02066\n",
      "Feature: 19, Score: 0.02584\n",
      "Feature: 20, Score: 0.01933\n",
      "Feature: 21, Score: 0.02488\n",
      "Feature: 22, Score: 0.02251\n",
      "Feature: 23, Score: 0.02039\n",
      "Feature: 24, Score: 0.01509\n",
      "Feature: 25, Score: 0.00031\n",
      "Feature: 26, Score: 0.00035\n",
      "Feature: 27, Score: 0.01042\n",
      "Feature: 28, Score: 0.00039\n",
      "Feature: 29, Score: 0.00036\n",
      "Feature: 30, Score: 0.00398\n",
      "Feature: 31, Score: 0.00335\n",
      "Feature: 32, Score: 0.00342\n",
      "Feature: 33, Score: 0.00943\n",
      "Feature: 34, Score: 0.00921\n",
      "Feature: 35, Score: 0.01006\n",
      "Feature: 36, Score: 0.00458\n",
      "Feature: 37, Score: 0.00091\n",
      "Feature: 38, Score: 0.00049\n",
      "Feature: 39, Score: 0.00466\n",
      "Feature: 40, Score: 0.00054\n",
      "Feature: 41, Score: 0.00039\n",
      "Feature: 42, Score: 0.00263\n",
      "Feature: 43, Score: 0.00223\n",
      "Feature: 44, Score: 0.00215\n",
      "Feature: 45, Score: 0.00151\n",
      "Feature: 46, Score: 0.00096\n",
      "Feature: 47, Score: 0.00096\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b958b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the important features, i.e importance greater than 0.01\n",
    "data_binary_new = data_binary.iloc[:, [6,7,8,9,10,11,12,15,18,19,20,21,22,23,24,27,35,48]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9f711",
   "metadata": {},
   "source": [
    "###### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f6dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>criterion</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter Best Value\n",
       "0          criterion    entropy\n",
       "1   min_samples_leaf          1\n",
       "2  min_samples_split          4\n",
       "3       n_estimators         80"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define x and y\n",
    "X = data_binary_new.iloc[:,:-1]\n",
    "y = data_binary_new.iloc[:,-1].astype(int)\n",
    "\n",
    "#split the data in to tran and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#parameters for tuning\n",
    "params = {\n",
    "    \"n_estimators\":list(range(60,101,10)), \n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1,5)), \n",
    "}\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "\n",
    "pd.DataFrame(best_params.items(), columns=['Parameter', 'Best Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b58316",
   "metadata": {},
   "source": [
    "###### Training the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "968aaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model with random forest classifier with best parameter\n",
    "clf_binary = RandomForestClassifier(**best_params)\n",
    "clf_binary.fit(X_train, y_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1b10d",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63ac6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                0       1  accuracy  macro avg  weighted avg\n",
      "precision     1.0     1.0       1.0        1.0           1.0\n",
      "recall        1.0     1.0       1.0        1.0           1.0\n",
      "f1-score      1.0     1.0       1.0        1.0           1.0\n",
      "support    3005.0  2949.0       1.0     5954.0        5954.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3005    0]\n",
      " [   0 2949]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_binary.predict(X_train)\n",
    "clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "print(\"Train Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71405171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.76%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.999206     0.996136   0.99765     0.997671      0.997655\n",
      "recall        0.996041     0.999225   0.99765     0.997633      0.997650\n",
      "f1-score      0.997621     0.997678   0.99765     0.997649      0.997650\n",
      "support    1263.000000  1290.000000   0.99765  2553.000000   2553.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1258    5]\n",
      " [   1 1289]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_binary.predict(X_test)\n",
    "clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "print(\"Test Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a2b0d",
   "metadata": {},
   "source": [
    "#### Multi Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c72ff9",
   "metadata": {},
   "source": [
    "###### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do descision tree classification with positive labels in default arguments\n",
    "# find feature importance and select important features\n",
    "\n",
    "X = data_multi.iloc[:,:-1]\n",
    "y = data_multi.iloc[:,-1].astype(int)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X, y)   \n",
    "importance = clf.feature_importances_              # get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "259180f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00347\n",
      "Feature: 1, Score: 0.00639\n",
      "Feature: 2, Score: 0.00082\n",
      "Feature: 3, Score: 0.00376\n",
      "Feature: 4, Score: 0.00798\n",
      "Feature: 5, Score: 0.00045\n",
      "Feature: 6, Score: 0.09958\n",
      "Feature: 7, Score: 0.12054\n",
      "Feature: 8, Score: 0.11179\n",
      "Feature: 9, Score: 0.16420\n",
      "Feature: 10, Score: 0.15486\n",
      "Feature: 11, Score: 0.14215\n",
      "Feature: 12, Score: 0.00870\n",
      "Feature: 13, Score: 0.00307\n",
      "Feature: 14, Score: 0.00276\n",
      "Feature: 15, Score: 0.00984\n",
      "Feature: 16, Score: 0.00342\n",
      "Feature: 17, Score: 0.00159\n",
      "Feature: 18, Score: 0.00963\n",
      "Feature: 19, Score: 0.00844\n",
      "Feature: 20, Score: 0.01048\n",
      "Feature: 21, Score: 0.00984\n",
      "Feature: 22, Score: 0.01239\n",
      "Feature: 23, Score: 0.00637\n",
      "Feature: 24, Score: 0.02822\n",
      "Feature: 25, Score: 0.00073\n",
      "Feature: 26, Score: 0.00030\n",
      "Feature: 27, Score: 0.01378\n",
      "Feature: 28, Score: 0.00053\n",
      "Feature: 29, Score: 0.00035\n",
      "Feature: 30, Score: 0.00747\n",
      "Feature: 31, Score: 0.00663\n",
      "Feature: 32, Score: 0.00464\n",
      "Feature: 33, Score: 0.00707\n",
      "Feature: 34, Score: 0.00657\n",
      "Feature: 35, Score: 0.00781\n",
      "Feature: 36, Score: 0.00256\n",
      "Feature: 37, Score: 0.00051\n",
      "Feature: 38, Score: 0.00044\n",
      "Feature: 39, Score: 0.00239\n",
      "Feature: 40, Score: 0.00068\n",
      "Feature: 41, Score: 0.00078\n",
      "Feature: 42, Score: 0.00133\n",
      "Feature: 43, Score: 0.00120\n",
      "Feature: 44, Score: 0.00129\n",
      "Feature: 45, Score: 0.00090\n",
      "Feature: 46, Score: 0.00062\n",
      "Feature: 47, Score: 0.00066\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f32c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select important features, i.e importance greater than 0.01\n",
    "data_multi_new = data_multi.iloc[:, [6,7,8,9,10,11,24,48]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880a2e8",
   "metadata": {},
   "source": [
    "###### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705ad63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "Best paramters: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 90})\n"
     ]
    }
   ],
   "source": [
    "#define x and y\n",
    "X = data_multi_new.iloc[:,:-1]\n",
    "y = data_multi_new.iloc[:,-1].astype(int)\n",
    "\n",
    "#split the data in to tran and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#parameters for tuning\n",
    "params = {\n",
    "    \"n_estimators\":list(range(60,101,10)), \n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1,5)), \n",
    "}\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3434e",
   "metadata": {},
   "source": [
    "###### Train the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59ec1557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model with random forest classifier with best parameters\n",
    "clf_multi = RandomForestClassifier(**best_params)\n",
    "clf_multi.fit(X_train, y_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7c2fe",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d60878ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.93%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               1           2           3           4           5  accuracy  \\\n",
      "precision    1.0    0.996503    1.000000    0.998888    1.000000  0.999326   \n",
      "recall       1.0    1.000000    0.997768    1.000000    0.998638  0.999326   \n",
      "f1-score     1.0    0.998249    0.998883    0.999444    0.999318  0.999326   \n",
      "support    602.0  285.000000  448.000000  898.000000  734.000000  0.999326   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.999078      0.999327  \n",
      "recall        0.999281      0.999326  \n",
      "f1-score      0.999179      0.999326  \n",
      "support    2967.000000   2967.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[602   0   0   0   0]\n",
      " [  0 285   0   0   0]\n",
      " [  0   0 447   1   0]\n",
      " [  0   0   0 898   0]\n",
      " [  0   1   0   0 733]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_multi.predict(X_train)\n",
    "clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "print(\"Train Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "882500e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 98.03%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               1           2           3           4           5  accuracy  \\\n",
      "precision    1.0    0.959350    0.975000    0.961538    0.997006  0.980346   \n",
      "recall       1.0    0.921875    0.960591    0.985915    0.994030  0.980346   \n",
      "f1-score     1.0    0.940239    0.967742    0.973574    0.995516  0.980346   \n",
      "support    251.0  128.000000  203.000000  355.000000  335.000000  0.980346   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.978579      0.980397  \n",
      "recall        0.972482      0.980346  \n",
      "f1-score      0.975414      0.980282  \n",
      "support    1272.000000   1272.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[251   0   0   0   0]\n",
      " [  0 118   2   7   1]\n",
      " [  0   1 195   7   0]\n",
      " [  0   2   3 350   0]\n",
      " [  0   2   0   0 333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_multi.predict(X_test)\n",
    "clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "print(\"Test Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7894d",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf60ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do binary classification, if output is zero update the output in csv as 'n'\n",
    "# if the output is 1(positive) do multi class classification\n",
    "# update output in the csv with labels p1, p2, p3, p4 or p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f64d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.520000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9797</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>5.6951</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5007</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.700000e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>-0.049183</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9604</td>\n",
       "      <td>-0.55811</td>\n",
       "      <td>9.603400</td>\n",
       "      <td>10.3340</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.680000e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>-0.026961</td>\n",
       "      <td>...</td>\n",
       "      <td>8.1376</td>\n",
       "      <td>-0.70769</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>10.5910</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.890000e-06</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6469</td>\n",
       "      <td>-0.63897</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>5.3556</td>\n",
       "      <td>-1.5076</td>\n",
       "      <td>-1.5077</td>\n",
       "      <td>-1.5068</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.910000e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1222</td>\n",
       "      <td>-0.47616</td>\n",
       "      <td>41.988000</td>\n",
       "      <td>4.0899</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0 -4.520000e-06  0.000002  0.000134 -0.000017 -0.000002 -0.000003  0.027720   \n",
       "1 -3.700000e-07  0.000002 -0.000007 -0.000002  0.000002  0.000001  0.025170   \n",
       "2 -8.680000e-06 -0.000005 -0.000058 -0.000005  0.000010  0.000045  0.027690   \n",
       "3 -3.890000e-06  0.000027 -0.000237  0.000019  0.000015  0.000877  0.018646   \n",
       "4 -3.910000e-07 -0.000003  0.000005  0.000002  0.000009 -0.000012  0.019145   \n",
       "\n",
       "          7         8         9  ...      38       39         40       41  \\\n",
       "0  0.027718  0.027584  0.027112  ...  3.9797 -0.62393   0.010489   5.6951   \n",
       "1  0.025168  0.025175 -0.049183  ...  7.9604 -0.55811   9.603400  10.3340   \n",
       "2  0.027695  0.027753 -0.026961  ...  8.1376 -0.70769   1.579500  10.5910   \n",
       "3  0.018619  0.018856 -0.032315  ...  4.6469 -0.63897   0.852670   5.3556   \n",
       "4  0.019149  0.019143  0.043739  ...  9.1222 -0.47616  41.988000   4.0899   \n",
       "\n",
       "       42      43      44      45      46      47  \n",
       "0 -1.5005 -1.5005 -1.5007 -1.4955 -1.4955 -1.4954  \n",
       "1 -1.4974 -1.4974 -1.4973 -1.4974 -1.4973 -1.4973  \n",
       "2 -1.4995 -1.4996 -1.4995 -1.4994 -1.4994 -1.4993  \n",
       "3 -1.5076 -1.5077 -1.5068 -1.4963 -1.4962 -1.4967  \n",
       "4 -1.4976 -1.4976 -1.4976 -1.4986 -1.4986 -1.4986  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "175de799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['y'] = [0  for i in range(len(test_data))]    #define output column with dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b16e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    X = np.array(test_data.iloc[i, [6,11,12,15,22,35,39]]).reshape(1,7)\n",
    "    y1 = clf_binary.predict(X)\n",
    "    \n",
    "    if y1 == 0:\n",
    "        test_data.loc[i,'y'] = 'n'\n",
    "    else:\n",
    "        X = np.array(test_data.iloc[i, [6,8,9,10,22,23,24]]).reshape(1,7)\n",
    "        y2 = clf_multi.predict(X)\n",
    "        \n",
    "        if y2 == 1:\n",
    "            test_data.loc[i,'y'] = 'p1'\n",
    "        elif y2 ==2:\n",
    "            test_data.loc[i,'y'] = 'p2'\n",
    "        elif y2 ==3:\n",
    "            test_data.loc[i,'y'] = 'p3'\n",
    "        elif y2 ==4:\n",
    "            test_data.loc[i,'y'] = 'p4'\n",
    "        elif y2 ==5:\n",
    "            test_data.loc[i,'y'] = 'p5'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5483a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.520000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>5.6951</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5007</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4954</td>\n",
       "      <td>p4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.700000e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>-0.049183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.55811</td>\n",
       "      <td>9.603400</td>\n",
       "      <td>10.3340</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.680000e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>-0.026961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.70769</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>10.5910</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4993</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.890000e-06</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63897</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>5.3556</td>\n",
       "      <td>-1.5076</td>\n",
       "      <td>-1.5077</td>\n",
       "      <td>-1.5068</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.910000e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47616</td>\n",
       "      <td>41.988000</td>\n",
       "      <td>4.0899</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>p3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0 -4.520000e-06  0.000002  0.000134 -0.000017 -0.000002 -0.000003  0.027720   \n",
       "1 -3.700000e-07  0.000002 -0.000007 -0.000002  0.000002  0.000001  0.025170   \n",
       "2 -8.680000e-06 -0.000005 -0.000058 -0.000005  0.000010  0.000045  0.027690   \n",
       "3 -3.890000e-06  0.000027 -0.000237  0.000019  0.000015  0.000877  0.018646   \n",
       "4 -3.910000e-07 -0.000003  0.000005  0.000002  0.000009 -0.000012  0.019145   \n",
       "\n",
       "          7         8         9  ...       39         40       41      42  \\\n",
       "0  0.027718  0.027584  0.027112  ... -0.62393   0.010489   5.6951 -1.5005   \n",
       "1  0.025168  0.025175 -0.049183  ... -0.55811   9.603400  10.3340 -1.4974   \n",
       "2  0.027695  0.027753 -0.026961  ... -0.70769   1.579500  10.5910 -1.4995   \n",
       "3  0.018619  0.018856 -0.032315  ... -0.63897   0.852670   5.3556 -1.5076   \n",
       "4  0.019149  0.019143  0.043739  ... -0.47616  41.988000   4.0899 -1.4976   \n",
       "\n",
       "       43      44      45      46      47   y  \n",
       "0 -1.5005 -1.5007 -1.4955 -1.4955 -1.4954  p4  \n",
       "1 -1.4974 -1.4973 -1.4974 -1.4973 -1.4973   n  \n",
       "2 -1.4996 -1.4995 -1.4994 -1.4994 -1.4993   n  \n",
       "3 -1.5077 -1.5068 -1.4963 -1.4962 -1.4967   n  \n",
       "4 -1.4976 -1.4976 -1.4986 -1.4986 -1.4986  p3  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4d788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
