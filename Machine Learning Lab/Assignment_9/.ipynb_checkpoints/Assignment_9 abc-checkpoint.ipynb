{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fc6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7298ed",
   "metadata": {},
   "source": [
    "### Question-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba654329",
   "metadata": {},
   "source": [
    "##### Learn a model which can classify given data correctly. This is a multiclass data imbalance problem with high dimensions data. You can see the classes are named as n, p1, p2, p3,...So the classes as n are negative ones and with p in it as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cff127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.190000e-06</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>p4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.080000e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-2.900000e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.031992</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49315</td>\n",
       "      <td>9.1182</td>\n",
       "      <td>15.4610</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.950000e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>p5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.680000e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610000e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>p5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2             3         4         5  \\\n",
       "0 -6.190000e-06 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116   \n",
       "1 -5.080000e-07 -0.000008 -0.000010 -2.900000e-06 -0.000001  0.000046   \n",
       "2  2.950000e-06  0.000036  0.000004  1.580000e-05  0.000098 -0.000337   \n",
       "3 -1.680000e-05  0.000026  0.000518  1.550000e-05  0.000072  0.000032   \n",
       "4  1.610000e-06  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036   \n",
       "\n",
       "          6         7         8         9  ...       39      40       41  \\\n",
       "0  0.027253  0.027290  0.027220  0.017966  ... -0.69694  1.6505   3.7807   \n",
       "1  0.031973  0.031981  0.031992 -0.036266  ... -0.49315  9.1182  15.4610   \n",
       "2  0.010780  0.010744  0.010740 -0.018368  ... -0.68272  1.8947   5.9028   \n",
       "3 -0.037939 -0.037965 -0.038483 -0.030257  ... -0.71862  1.9076   5.5017   \n",
       "4  0.010411  0.010393  0.010549 -0.014548  ... -0.71715  1.0778   4.9960   \n",
       "\n",
       "       42      43      44      45      46      47  48  \n",
       "0 -1.5016 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940  p4  \n",
       "1 -1.4980 -1.4980 -1.4980 -1.4978 -1.4978 -1.4978   n  \n",
       "2 -1.4970 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036  p5  \n",
       "3 -1.4962 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017  p1  \n",
       "4 -1.5042 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915  p5  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d336616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8.507000e+03</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "      <td>8507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-8.104282e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.015471</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>-0.016507</td>\n",
       "      <td>...</td>\n",
       "      <td>8.297015</td>\n",
       "      <td>-0.635826</td>\n",
       "      <td>7.031227</td>\n",
       "      <td>8.142438</td>\n",
       "      <td>-1.501420</td>\n",
       "      <td>-1.501451</td>\n",
       "      <td>-1.501339</td>\n",
       "      <td>-1.497626</td>\n",
       "      <td>-1.497649</td>\n",
       "      <td>-1.497529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>8.580479e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>...</td>\n",
       "      <td>6.660245</td>\n",
       "      <td>1.607126</td>\n",
       "      <td>11.689025</td>\n",
       "      <td>6.417985</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.003015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.002209</td>\n",
       "      <td>-4.170000e-05</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>-0.055309</td>\n",
       "      <td>-0.055316</td>\n",
       "      <td>-0.055328</td>\n",
       "      <td>-0.061243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712110</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>-0.535610</td>\n",
       "      <td>0.606140</td>\n",
       "      <td>-1.512400</td>\n",
       "      <td>-1.512400</td>\n",
       "      <td>-1.511800</td>\n",
       "      <td>-1.510400</td>\n",
       "      <td>-1.510400</td>\n",
       "      <td>-1.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-5.435000e-06</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.035379</td>\n",
       "      <td>...</td>\n",
       "      <td>4.409750</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>1.500250</td>\n",
       "      <td>4.322250</td>\n",
       "      <td>-1.504100</td>\n",
       "      <td>-1.504100</td>\n",
       "      <td>-1.504000</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>-1.499300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.740000e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.028206</td>\n",
       "      <td>...</td>\n",
       "      <td>6.496200</td>\n",
       "      <td>-0.668240</td>\n",
       "      <td>3.235400</td>\n",
       "      <td>6.343600</td>\n",
       "      <td>-1.500800</td>\n",
       "      <td>-1.500800</td>\n",
       "      <td>-1.500700</td>\n",
       "      <td>-1.497900</td>\n",
       "      <td>-1.497900</td>\n",
       "      <td>-1.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>3.790000e-06</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.025535</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>...</td>\n",
       "      <td>9.822150</td>\n",
       "      <td>-0.578400</td>\n",
       "      <td>7.891750</td>\n",
       "      <td>9.731400</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.498500</td>\n",
       "      <td>-1.496100</td>\n",
       "      <td>-1.496100</td>\n",
       "      <td>-1.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>7.080000e-05</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.046319</td>\n",
       "      <td>0.046329</td>\n",
       "      <td>0.071934</td>\n",
       "      <td>...</td>\n",
       "      <td>89.372000</td>\n",
       "      <td>146.340000</td>\n",
       "      <td>145.860000</td>\n",
       "      <td>98.758000</td>\n",
       "      <td>-1.458500</td>\n",
       "      <td>-1.466200</td>\n",
       "      <td>-1.472600</td>\n",
       "      <td>-1.488400</td>\n",
       "      <td>-1.488400</td>\n",
       "      <td>-1.486800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2             3            4  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8.507000e+03  8507.000000   \n",
       "mean     -0.000001     0.000007     0.000015 -8.104282e-07     0.000010   \n",
       "std       0.000064     0.000069     0.000230  8.580479e-06     0.000038   \n",
       "min      -0.000678    -0.002163    -0.002209 -4.170000e-05    -0.000260   \n",
       "25%      -0.000006    -0.000007    -0.000065 -5.435000e-06    -0.000006   \n",
       "50%      -0.000002     0.000004     0.000003 -1.740000e-06     0.000004   \n",
       "75%       0.000002     0.000026     0.000089  3.790000e-06     0.000029   \n",
       "max       0.005784     0.004525     0.003330  7.080000e-05     0.000348   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000  ...   \n",
       "mean      0.000011     0.015471     0.015463     0.015448    -0.016507  ...   \n",
       "std       0.000217     0.015712     0.015715     0.015722     0.027911  ...   \n",
       "min      -0.001626    -0.055309    -0.055316    -0.055328    -0.061243  ...   \n",
       "25%      -0.000065     0.012665     0.012656     0.012658    -0.035379  ...   \n",
       "50%       0.000002     0.019684     0.019680     0.019674    -0.028206  ...   \n",
       "75%       0.000078     0.025535     0.025531     0.025518     0.004998  ...   \n",
       "max       0.001982     0.046324     0.046319     0.046329     0.071934  ...   \n",
       "\n",
       "                38           39           40           41           42  \\\n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000   \n",
       "mean      8.297015    -0.635826     7.031227     8.142438    -1.501420   \n",
       "std       6.660245     1.607126    11.689025     6.417985     0.003717   \n",
       "min       0.712110    -0.891000    -0.535610     0.606140    -1.512400   \n",
       "25%       4.409750    -0.717045     1.500250     4.322250    -1.504100   \n",
       "50%       6.496200    -0.668240     3.235400     6.343600    -1.500800   \n",
       "75%       9.822150    -0.578400     7.891750     9.731400    -1.498500   \n",
       "max      89.372000   146.340000   145.860000    98.758000    -1.458500   \n",
       "\n",
       "                43           44           45           46           47  \n",
       "count  8507.000000  8507.000000  8507.000000  8507.000000  8507.000000  \n",
       "mean     -1.501451    -1.501339    -1.497626    -1.497649    -1.497529  \n",
       "std       0.003720     0.003670     0.002998     0.002996     0.003015  \n",
       "min      -1.512400    -1.511800    -1.510400    -1.510400    -1.510500  \n",
       "25%      -1.504100    -1.504000    -1.499400    -1.499400    -1.499300  \n",
       "50%      -1.500800    -1.500700    -1.497900    -1.497900    -1.497800  \n",
       "75%      -1.498500    -1.498500    -1.496100    -1.496100    -1.496000  \n",
       "max      -1.466200    -1.472600    -1.488400    -1.488400    -1.486800  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9158a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples                    :8507\n",
      "No.of samples with label 'n'      :4268\n",
      "No.of samples with label 'p1'     :853\n",
      "No.of samples with label 'p2'     :413\n",
      "No.of samples with label 'p3'     :651\n",
      "No.of samples with label 'p4'     :1253\n",
      "No.of samples with label 'p5'     :1069\n"
     ]
    }
   ],
   "source": [
    "# number of samples and count of each samples\n",
    "print(f\"No. of samples                    :{len(data)}\")\n",
    "print(f\"No.of samples with label 'n'      :{len(data[data.iloc[:,48]=='n'])}\")\n",
    "print(f\"No.of samples with label 'p1'     :{len(data[data.iloc[:,48]=='p1'])}\")\n",
    "print(f\"No.of samples with label 'p2'     :{len(data[data.iloc[:,48]=='p2'])}\")\n",
    "print(f\"No.of samples with label 'p3'     :{len(data[data.iloc[:,48]=='p3'])}\")\n",
    "print(f\"No.of samples with label 'p4'     :{len(data[data.iloc[:,48]=='p4'])}\")\n",
    "print(f\"No.of samples with label 'p5'     :{len(data[data.iloc[:,48]=='p5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb61a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is highly imbalanced, so split the data into positive and negative\n",
    "# all 'pi' labels as positive(1) and all 'n' label as negative(0)\n",
    "# do binary classification with this dataset\n",
    "# then split all positive labels in to p1, p2, p3, p4, and p5\n",
    "# do multilabel classification with this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea176707",
   "metadata": {},
   "source": [
    "###### Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf52dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.190000e-06</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.080000e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-2.900000e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.031981</td>\n",
       "      <td>0.031992</td>\n",
       "      <td>-0.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49315</td>\n",
       "      <td>9.1182</td>\n",
       "      <td>15.4610</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>-1.4978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.950000e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.680000e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.610000e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2             3         4         5  \\\n",
       "0 -6.190000e-06 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116   \n",
       "1 -5.080000e-07 -0.000008 -0.000010 -2.900000e-06 -0.000001  0.000046   \n",
       "2  2.950000e-06  0.000036  0.000004  1.580000e-05  0.000098 -0.000337   \n",
       "3 -1.680000e-05  0.000026  0.000518  1.550000e-05  0.000072  0.000032   \n",
       "4  1.610000e-06  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036   \n",
       "\n",
       "          6         7         8         9  ...       39      40       41  \\\n",
       "0  0.027253  0.027290  0.027220  0.017966  ... -0.69694  1.6505   3.7807   \n",
       "1  0.031973  0.031981  0.031992 -0.036266  ... -0.49315  9.1182  15.4610   \n",
       "2  0.010780  0.010744  0.010740 -0.018368  ... -0.68272  1.8947   5.9028   \n",
       "3 -0.037939 -0.037965 -0.038483 -0.030257  ... -0.71862  1.9076   5.5017   \n",
       "4  0.010411  0.010393  0.010549 -0.014548  ... -0.71715  1.0778   4.9960   \n",
       "\n",
       "       42      43      44      45      46      47  48  \n",
       "0 -1.5016 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940   1  \n",
       "1 -1.4980 -1.4980 -1.4980 -1.4978 -1.4978 -1.4978   0  \n",
       "2 -1.4970 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036   1  \n",
       "3 -1.4962 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017   1  \n",
       "4 -1.5042 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915   1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data split into positive and negative labels\n",
    "data_binary = data.copy()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data_binary.iloc[i,-1] == 'n':\n",
    "        data_binary.iloc[i,-1] = 0                 #put n label as 0 and others as 1\n",
    "    else:\n",
    "        data_binary.iloc[i,-1] = 1\n",
    "\n",
    "data_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb1ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-2.560000e-05</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69694</td>\n",
       "      <td>1.6505</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>-1.5016</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4939</td>\n",
       "      <td>-1.4940</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.580000e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>-0.018368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68272</td>\n",
       "      <td>1.8947</td>\n",
       "      <td>5.9028</td>\n",
       "      <td>-1.4970</td>\n",
       "      <td>-1.4971</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.5038</td>\n",
       "      <td>-1.5039</td>\n",
       "      <td>-1.5036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.550000e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>-0.038483</td>\n",
       "      <td>-0.030257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71862</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>5.5017</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4960</td>\n",
       "      <td>-1.5020</td>\n",
       "      <td>-1.5021</td>\n",
       "      <td>-1.5017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-9.650000e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71715</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>4.9960</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5042</td>\n",
       "      <td>-1.5041</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4911</td>\n",
       "      <td>-1.4915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-1.330000e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.019514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68758</td>\n",
       "      <td>11.5330</td>\n",
       "      <td>30.4150</td>\n",
       "      <td>-1.4991</td>\n",
       "      <td>-1.4992</td>\n",
       "      <td>-1.4993</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2             3         4         5         6  \\\n",
       "0 -0.000006 -0.000037  0.000070 -2.560000e-05 -0.000041 -0.000116  0.027253   \n",
       "2  0.000003  0.000036  0.000004  1.580000e-05  0.000098 -0.000337  0.010780   \n",
       "3 -0.000017  0.000026  0.000518  1.550000e-05  0.000072  0.000032 -0.037939   \n",
       "4  0.000002  0.000018 -0.000156 -9.650000e-07  0.000009  0.000036  0.010411   \n",
       "8 -0.000002 -0.000016  0.000046 -1.330000e-06  0.000008 -0.000092  0.011017   \n",
       "\n",
       "          7         8         9  ...       39       40       41      42  \\\n",
       "0  0.027290  0.027220  0.017966  ... -0.69694   1.6505   3.7807 -1.5016   \n",
       "2  0.010744  0.010740 -0.018368  ... -0.68272   1.8947   5.9028 -1.4970   \n",
       "3 -0.037965 -0.038483 -0.030257  ... -0.71862   1.9076   5.5017 -1.4962   \n",
       "4  0.010393  0.010549 -0.014548  ... -0.71715   1.0778   4.9960 -1.5042   \n",
       "8  0.011033  0.010987  0.019514  ... -0.68758  11.5330  30.4150 -1.4991   \n",
       "\n",
       "       43      44      45      46      47  48  \n",
       "0 -1.5017 -1.5016 -1.4939 -1.4939 -1.4940   4  \n",
       "2 -1.4971 -1.4972 -1.5038 -1.5039 -1.5036   5  \n",
       "3 -1.4963 -1.4960 -1.5020 -1.5021 -1.5017   1  \n",
       "4 -1.5042 -1.5041 -1.4911 -1.4911 -1.4915   5  \n",
       "8 -1.4992 -1.4993 -1.4986 -1.4986 -1.4984   2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for multi class classification\n",
    "# p1=1, p2=2, p3=3, p4=4, p5=5 \n",
    "data_multi = data[data.iloc[:,-1]!= 'n']       \n",
    "\n",
    "for i in range(len(data_multi)):\n",
    "    if data_multi.iloc[i,-1] == 'p1':\n",
    "        data_multi.iloc[i,-1] = 1\n",
    "    elif data_multi.iloc[i,-1] == 'p2':\n",
    "        data_multi.iloc[i,-1] = 2\n",
    "    elif data_multi.iloc[i,-1] == 'p3':\n",
    "        data_multi.iloc[i,-1] = 3\n",
    "    elif data_multi.iloc[i,-1] == 'p4':\n",
    "        data_multi.iloc[i,-1] = 4\n",
    "    elif data_multi.iloc[i,-1] == 'p5':\n",
    "        data_multi.iloc[i,-1] = 5\n",
    "\n",
    "data_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd920e",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c70ce",
   "metadata": {},
   "source": [
    "###### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a479c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do descision tree classification with positive and negative data in default arguments\n",
    "# find feature importance and select important features\n",
    "\n",
    "X = data_binary.iloc[:,:-1]\n",
    "y = data_binary.iloc[:,-1].astype(int)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X, y)   \n",
    "importance = clf.feature_importances_              # get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de179a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00038\n",
      "Feature: 1, Score: 0.00043\n",
      "Feature: 2, Score: 0.00031\n",
      "Feature: 3, Score: 0.00002\n",
      "Feature: 4, Score: 0.00000\n",
      "Feature: 5, Score: 0.00000\n",
      "Feature: 6, Score: 0.32385\n",
      "Feature: 7, Score: 0.01785\n",
      "Feature: 8, Score: 0.00150\n",
      "Feature: 9, Score: 0.00504\n",
      "Feature: 10, Score: 0.00071\n",
      "Feature: 11, Score: 0.44082\n",
      "Feature: 12, Score: 0.02898\n",
      "Feature: 13, Score: 0.00000\n",
      "Feature: 14, Score: 0.00132\n",
      "Feature: 15, Score: 0.06647\n",
      "Feature: 16, Score: 0.01956\n",
      "Feature: 17, Score: 0.00084\n",
      "Feature: 18, Score: 0.00000\n",
      "Feature: 19, Score: 0.01366\n",
      "Feature: 20, Score: 0.00258\n",
      "Feature: 21, Score: 0.00186\n",
      "Feature: 22, Score: 0.00344\n",
      "Feature: 23, Score: 0.02810\n",
      "Feature: 24, Score: 0.00035\n",
      "Feature: 25, Score: 0.00046\n",
      "Feature: 26, Score: 0.00003\n",
      "Feature: 27, Score: 0.00045\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00090\n",
      "Feature: 30, Score: 0.00047\n",
      "Feature: 31, Score: 0.00555\n",
      "Feature: 32, Score: 0.00167\n",
      "Feature: 33, Score: 0.00155\n",
      "Feature: 34, Score: 0.00000\n",
      "Feature: 35, Score: 0.01129\n",
      "Feature: 36, Score: 0.00136\n",
      "Feature: 37, Score: 0.00023\n",
      "Feature: 38, Score: 0.00072\n",
      "Feature: 39, Score: 0.01281\n",
      "Feature: 40, Score: 0.00020\n",
      "Feature: 41, Score: 0.00006\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00077\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00142\n",
      "Feature: 46, Score: 0.00201\n",
      "Feature: 47, Score: 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b958b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the important features, i.e importance greater than 0.01\n",
    "data_binary_new = data_binary.iloc[:, [6,11,12,15,22,35,39,48]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9f711",
   "metadata": {},
   "source": [
    "###### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5f6dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "Best paramters: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 80})\n"
     ]
    }
   ],
   "source": [
    "#define x and y\n",
    "X = data_binary_new.iloc[:,:-1]\n",
    "y = data_binary_new.iloc[:,-1].astype(int)\n",
    "\n",
    "#split the data in to tran and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#parameters for tuning\n",
    "params = {\n",
    "    \"n_estimators\":list(range(60,101,10)), \n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1,5)), \n",
    "}\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b58316",
   "metadata": {},
   "source": [
    "###### Training the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "968aaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model with random forest classifier with best parameter\n",
    "clf_binary = RandomForestClassifier(**best_params)\n",
    "clf_binary.fit(X_train, y_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1b10d",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63ac6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                0       1  accuracy  macro avg  weighted avg\n",
      "precision     1.0     1.0       1.0        1.0           1.0\n",
      "recall        1.0     1.0       1.0        1.0           1.0\n",
      "f1-score      1.0     1.0       1.0        1.0           1.0\n",
      "support    3005.0  2949.0       1.0     5954.0        5954.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3005    0]\n",
      " [   0 2949]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_binary.predict(X_train)\n",
    "clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "print(\"Train Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71405171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.80%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     1.000000     0.996139  0.998042     0.998069      0.998049\n",
      "recall        0.996041     1.000000  0.998042     0.998021      0.998042\n",
      "f1-score      0.998017     0.998066  0.998042     0.998041      0.998041\n",
      "support    1263.000000  1290.000000  0.998042  2553.000000   2553.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1258    5]\n",
      " [   0 1290]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_binary.predict(X_test)\n",
    "clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "print(\"Test Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a2b0d",
   "metadata": {},
   "source": [
    "#### Multi Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c72ff9",
   "metadata": {},
   "source": [
    "###### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f42778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do descision tree classification with positive labels in default arguments\n",
    "# find feature importance and select important features\n",
    "\n",
    "X = data_multi.iloc[:,:-1]\n",
    "y = data_multi.iloc[:,-1].astype(int)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X, y)   \n",
    "importance = clf.feature_importances_              # get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "259180f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00090\n",
      "Feature: 1, Score: 0.00000\n",
      "Feature: 2, Score: 0.00030\n",
      "Feature: 3, Score: 0.00167\n",
      "Feature: 4, Score: 0.00098\n",
      "Feature: 5, Score: 0.00012\n",
      "Feature: 6, Score: 0.39997\n",
      "Feature: 7, Score: 0.00276\n",
      "Feature: 8, Score: 0.01669\n",
      "Feature: 9, Score: 0.00139\n",
      "Feature: 10, Score: 0.48978\n",
      "Feature: 11, Score: 0.00049\n",
      "Feature: 12, Score: 0.00201\n",
      "Feature: 13, Score: 0.00103\n",
      "Feature: 14, Score: 0.00060\n",
      "Feature: 15, Score: 0.00979\n",
      "Feature: 16, Score: 0.00000\n",
      "Feature: 17, Score: 0.00000\n",
      "Feature: 18, Score: 0.00000\n",
      "Feature: 19, Score: 0.00000\n",
      "Feature: 20, Score: 0.00000\n",
      "Feature: 21, Score: 0.00030\n",
      "Feature: 22, Score: 0.01534\n",
      "Feature: 23, Score: 0.01004\n",
      "Feature: 24, Score: 0.03991\n",
      "Feature: 25, Score: 0.00000\n",
      "Feature: 26, Score: 0.00000\n",
      "Feature: 27, Score: 0.00138\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00000\n",
      "Feature: 30, Score: 0.00000\n",
      "Feature: 31, Score: 0.00060\n",
      "Feature: 32, Score: 0.00000\n",
      "Feature: 33, Score: 0.00000\n",
      "Feature: 34, Score: 0.00059\n",
      "Feature: 35, Score: 0.00000\n",
      "Feature: 36, Score: 0.00240\n",
      "Feature: 37, Score: 0.00000\n",
      "Feature: 38, Score: 0.00000\n",
      "Feature: 39, Score: 0.00065\n",
      "Feature: 40, Score: 0.00000\n",
      "Feature: 41, Score: 0.00000\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00000\n",
      "Feature: 44, Score: 0.00030\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5f32c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select important features, i.e importance greater than 0.01\n",
    "data_multi_new = data_multi.iloc[:, [6,8,9,10,22,23,24,48]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880a2e8",
   "metadata": {},
   "source": [
    "###### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "705ad63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "Best paramters: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 80})\n"
     ]
    }
   ],
   "source": [
    "#define x and y\n",
    "X = data_multi_new.iloc[:,:-1]\n",
    "y = data_multi_new.iloc[:,-1].astype(int)\n",
    "\n",
    "#split the data in to tran and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#parameters for tuning\n",
    "params = {\n",
    "    \"n_estimators\":list(range(60,101,10)), \n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1,5)), \n",
    "}\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3434e",
   "metadata": {},
   "source": [
    "###### Train the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59ec1557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model with random forest classifier with best parameters\n",
    "clf_multi = RandomForestClassifier(**best_params)\n",
    "clf_multi.fit(X_train, y_train)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7c2fe",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d60878ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               1      2      3      4      5  accuracy  macro avg  \\\n",
      "precision    1.0    1.0    1.0    1.0    1.0       1.0        1.0   \n",
      "recall       1.0    1.0    1.0    1.0    1.0       1.0        1.0   \n",
      "f1-score     1.0    1.0    1.0    1.0    1.0       1.0        1.0   \n",
      "support    602.0  285.0  448.0  898.0  734.0       1.0     2967.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support          2967.0  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[602   0   0   0   0]\n",
      " [  0 285   0   0   0]\n",
      " [  0   0 448   0   0]\n",
      " [  0   0   0 898   0]\n",
      " [  0   0   0   0 734]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_multi.predict(X_train)\n",
    "clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "print(\"Train Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "882500e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.53%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               1           2           3           4           5  accuracy  \\\n",
      "precision    1.0    1.000000    0.990196    0.991573    0.997024  0.995283   \n",
      "recall       1.0    0.976562    0.995074    0.994366    1.000000  0.995283   \n",
      "f1-score     1.0    0.988142    0.992629    0.992968    0.998510  0.995283   \n",
      "support    251.0  128.000000  203.000000  355.000000  335.000000  0.995283   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.995759      0.995300  \n",
      "recall        0.993201      0.995283  \n",
      "f1-score      0.994450      0.995275  \n",
      "support    1272.000000   1272.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[251   0   0   0   0]\n",
      " [  0 125   0   2   1]\n",
      " [  0   0 202   1   0]\n",
      " [  0   0   2 353   0]\n",
      " [  0   0   0   0 335]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf_multi.predict(X_test)\n",
    "clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "print(\"Test Result:\\n================================================\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "print(\"_______________________________________________\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7894d",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf60ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do binary classification, if output is zero update the output in csv as 'n'\n",
    "# if the output is 1(positive) do multi class classification\n",
    "# update output in the csv with labels p1, p2, p3, p4 or p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f64d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.520000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9797</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>5.6951</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5007</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.700000e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>-0.049183</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9604</td>\n",
       "      <td>-0.55811</td>\n",
       "      <td>9.603400</td>\n",
       "      <td>10.3340</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.680000e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>-0.026961</td>\n",
       "      <td>...</td>\n",
       "      <td>8.1376</td>\n",
       "      <td>-0.70769</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>10.5910</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.890000e-06</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6469</td>\n",
       "      <td>-0.63897</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>5.3556</td>\n",
       "      <td>-1.5076</td>\n",
       "      <td>-1.5077</td>\n",
       "      <td>-1.5068</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.910000e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1222</td>\n",
       "      <td>-0.47616</td>\n",
       "      <td>41.988000</td>\n",
       "      <td>4.0899</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0 -4.520000e-06  0.000002  0.000134 -0.000017 -0.000002 -0.000003  0.027720   \n",
       "1 -3.700000e-07  0.000002 -0.000007 -0.000002  0.000002  0.000001  0.025170   \n",
       "2 -8.680000e-06 -0.000005 -0.000058 -0.000005  0.000010  0.000045  0.027690   \n",
       "3 -3.890000e-06  0.000027 -0.000237  0.000019  0.000015  0.000877  0.018646   \n",
       "4 -3.910000e-07 -0.000003  0.000005  0.000002  0.000009 -0.000012  0.019145   \n",
       "\n",
       "          7         8         9  ...      38       39         40       41  \\\n",
       "0  0.027718  0.027584  0.027112  ...  3.9797 -0.62393   0.010489   5.6951   \n",
       "1  0.025168  0.025175 -0.049183  ...  7.9604 -0.55811   9.603400  10.3340   \n",
       "2  0.027695  0.027753 -0.026961  ...  8.1376 -0.70769   1.579500  10.5910   \n",
       "3  0.018619  0.018856 -0.032315  ...  4.6469 -0.63897   0.852670   5.3556   \n",
       "4  0.019149  0.019143  0.043739  ...  9.1222 -0.47616  41.988000   4.0899   \n",
       "\n",
       "       42      43      44      45      46      47  \n",
       "0 -1.5005 -1.5005 -1.5007 -1.4955 -1.4955 -1.4954  \n",
       "1 -1.4974 -1.4974 -1.4973 -1.4974 -1.4973 -1.4973  \n",
       "2 -1.4995 -1.4996 -1.4995 -1.4994 -1.4994 -1.4993  \n",
       "3 -1.5076 -1.5077 -1.5068 -1.4963 -1.4962 -1.4967  \n",
       "4 -1.4976 -1.4976 -1.4976 -1.4986 -1.4986 -1.4986  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "175de799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['y'] = [0  for i in range(len(test_data))]    #define output column with dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b16e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    X = np.array(test_data.iloc[i, [6,11,12,15,22,35,39]]).reshape(1,7)\n",
    "    y1 = clf_binary.predict(X)\n",
    "    \n",
    "    if y1 == 0:\n",
    "        test_data.loc[i,'y'] = 'n'\n",
    "    else:\n",
    "        X = np.array(test_data.iloc[i, [6,8,9,10,22,23,24]]).reshape(1,7)\n",
    "        y2 = clf_multi.predict(X)\n",
    "        \n",
    "        if y2 == 1:\n",
    "            test_data.loc[i,'y'] = 'p1'\n",
    "        elif y2 ==2:\n",
    "            test_data.loc[i,'y'] = 'p2'\n",
    "        elif y2 ==3:\n",
    "            test_data.loc[i,'y'] = 'p3'\n",
    "        elif y2 ==4:\n",
    "            test_data.loc[i,'y'] = 'p4'\n",
    "        elif y2 ==5:\n",
    "            test_data.loc[i,'y'] = 'p5'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5483a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.520000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>5.6951</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5007</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>-1.4954</td>\n",
       "      <td>p4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.700000e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>-0.049183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.55811</td>\n",
       "      <td>9.603400</td>\n",
       "      <td>10.3340</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4974</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.680000e-06</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>-0.026961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.70769</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>10.5910</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4993</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.890000e-06</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>-0.032315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63897</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>5.3556</td>\n",
       "      <td>-1.5076</td>\n",
       "      <td>-1.5077</td>\n",
       "      <td>-1.5068</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4962</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.910000e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47616</td>\n",
       "      <td>41.988000</td>\n",
       "      <td>4.0899</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>-1.4986</td>\n",
       "      <td>p3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0 -4.520000e-06  0.000002  0.000134 -0.000017 -0.000002 -0.000003  0.027720   \n",
       "1 -3.700000e-07  0.000002 -0.000007 -0.000002  0.000002  0.000001  0.025170   \n",
       "2 -8.680000e-06 -0.000005 -0.000058 -0.000005  0.000010  0.000045  0.027690   \n",
       "3 -3.890000e-06  0.000027 -0.000237  0.000019  0.000015  0.000877  0.018646   \n",
       "4 -3.910000e-07 -0.000003  0.000005  0.000002  0.000009 -0.000012  0.019145   \n",
       "\n",
       "          7         8         9  ...       39         40       41      42  \\\n",
       "0  0.027718  0.027584  0.027112  ... -0.62393   0.010489   5.6951 -1.5005   \n",
       "1  0.025168  0.025175 -0.049183  ... -0.55811   9.603400  10.3340 -1.4974   \n",
       "2  0.027695  0.027753 -0.026961  ... -0.70769   1.579500  10.5910 -1.4995   \n",
       "3  0.018619  0.018856 -0.032315  ... -0.63897   0.852670   5.3556 -1.5076   \n",
       "4  0.019149  0.019143  0.043739  ... -0.47616  41.988000   4.0899 -1.4976   \n",
       "\n",
       "       43      44      45      46      47   y  \n",
       "0 -1.5005 -1.5007 -1.4955 -1.4955 -1.4954  p4  \n",
       "1 -1.4974 -1.4973 -1.4974 -1.4973 -1.4973   n  \n",
       "2 -1.4996 -1.4995 -1.4994 -1.4994 -1.4993   n  \n",
       "3 -1.5077 -1.5068 -1.4963 -1.4962 -1.4967   n  \n",
       "4 -1.4976 -1.4976 -1.4986 -1.4986 -1.4986  p3  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4d788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
